For each thread, it sets a starting key and computes 
the public key using the secp->ComputePublicKey(&k) function

Public Key Computation: After computing the starting keys, 
public keys are generated and stored in an array (p).





--- keys[0] - tRangeDiff  : 2832ED74F005E3500 - 27555 -----
--- keys[1] - tRangeDiff  : 2832ED74F0060AA55 - 27555 -----
--- keys[2] - tRangeDiff  : 2832ED74F00631FAA - 27555 -----
--- keys[6142] - tRangeDiff  : 2832ED74F3B594256 - 27555 -----
--- keys[6143] - tRangeDiff  : 2832ED74F3B5BB7AB - 27555 -----



keys[0] : 2832ED74F005E3D00
keys[1] : 2832ED74F0060B255
keys[2] : 2832ED74F006327AA
keys[6142] : 2832ED74F3B594A56
keys[6143] : 2832ED74F3B5BBFAB

--- keys[thId = 128 ] : 2832ED74F0198E780 -----
--- counters : 12582912 -----

keys[0] : 2832ED74F005E4500
keys[1] : 2832ED74F0060BA55
keys[2] : 2832ED74F00632FAA
keys[6142] : 2832ED74F3B595256
keys[6143] : 2832ED74F3B5BC7AB
--- keys[thId = 128 ] : 2832ED74F0198EF80 -----
--- counters : 25165824 -----


keys[0] : 2832ED74F005E4D00
keys[1] : 2832ED74F0060C255
keys[2] : 2832ED74F006337AA
keys[6142] : 2832ED74F3B595A56
keys[6143] : 2832ED74F3B5BCFAB
























// ----------------------------------------------------------------------------
void KeyHunt::getGPUStartingKeys(Int & tRangeStart, Int & tRangeEnd, int groupSize, int nbThread, Int * keys, Point * p)
{
	printf("\n::::::K::::::: KeyHunt::getGPUStarting_Keys() ::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::\n");

	Int tRangeDiff(tRangeEnd);
	Int tRangeStart2(tRangeStart);
	Int tRangeEnd2(tRangeStart);

	Int tThreads;
	tThreads.SetInt32(nbThread);
	tRangeDiff.Set(&tRangeEnd);
	tRangeDiff.Sub(&tRangeStart);
	tRangeDiff.Div(&tThreads);

					std::cout <<"------tR diff   : 175 : " << tRangeDiff.GetBase16().c_str() << std::endl;
					std::cout <<"------tR start  : 175 : " << tRangeStart.GetBase16().c_str() << std::endl;
					std::cout <<"------tR end    : 175 : " << tRangeEnd.GetBase16().c_str() << std::endl;
					std::cout <<"------tR start2 : 175 : " << tRangeStart2.GetBase16().c_str() << std::endl;
					std::cout <<"------tR end2   : 175 : " << tRangeEnd2.GetBase16().c_str() << std::endl;
					std::cout << std::endl<<"------tRangeDiff.Div(nbThread) : 186 : " << tRangeDiff.GetBase16().c_str() << std::endl << std::endl;


	for (int i = 0; i < nbThread; i++) { //nbThread = 6144

		tRangeEnd2.Set(&tRangeStart2);  
		tRangeEnd2.Add(&tRangeDiff); 
		keys[i].Set(&tRangeStart2);  // set keys[i] tổng thể cho từng thread
		if (i==0 || i==1 || i==2 || i == nbThread-2 || i == nbThread-1 || i == nbThread){
			printf("\n --- keys[%d] - tRangeDiff  : %s - %s -----  ",i ,keys[i].GetBase16().c_str() , tRangeDiff.GetBase16().c_str());
		}
		tRangeStart2.Add(&tRangeDiff);

		Int k(keys + i);
		k.Add((uint64_t)(groupSize / 2));	// Starting key is at the middle of the group // groupSize =  GRP_SIZE (1024*2)		// hiiu.... ko hiểu đoạn ở giữa group là gì
		p[i] = secp->ComputePublicKey(&k);  //----sau đó đc truyền vào ------> ok = GPU_Engine->SetKeys(p);
		//k is an Int object that you created for key handling. The & operator gets its address, allowing the public key computation to operate directly on this variable
		//Point Secp256K1::ComputePublicKey(Int* privKey) 
		//The public key for the generated starting key is computed using secp->ComputePublicKey(&k) and stored in the p array
	}
}

void KeyHunt::FindKeyGPU(TH_PARAM * ph)
{
	printf("\n::::::K::::::: KeyHunt::FindKeyGP_U ::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::");
	bool ok = true;

	// Global init
	int thId = ph->threadId;
	Int tRangeStart = ph->rangeStart;
	Int tRangeEnd = ph->rangeEnd;

	// std::cout<<"----- tRangeStart 209 : "<< tRangeStart.GetBase16().c_str() << std::endl;
	// std::cout<<"----- tRangeEnd 310   : "<< tRangeEnd.GetBase16().c_str() << std::endl;

	GPUEngine* GPU_Engine;
	GPU_Engine = new GPUEngine(secp, ph->gridSizeX, ph->gridSizeY, ph->gpuId, maxFound, searchMode, compMode, coinType, hash160Keccak);  //---------------- dòng 50 -----hash160Keccak = hashORxpoint
	printf("GPU info      : %s\n\n", GPU_Engine->deviceName.c_str());

	int nbThread = GPU_Engine->GetNbThread(); //6144
	std::cout << "-------------------nbThread  : "<< nbThread << std::endl << std::endl; // 6144

	Point* p = new Point[nbThread]; // p này để lưu giá trị của public_key  --- trong hàm getGPUStartingKey_s 
	Int* keys = new Int[nbThread];
	std::vector<ITEM> found;
	counters[thId] = 0;
	ph->hasStarted = true;
	

	getGPUStartingKeys(tRangeStart, tRangeEnd, GPU_Engine->GetGroupSize(), nbThread, keys, p);
	ok = GPU_Engine->SetKeys(p);    //-------> chạy 1 lần compute <<<>>>

	// GPU_Engine Thread
	while (ok && !endOfSearch) {
		ok = GPU_Engine->LaunchSEARCH_MODE_SA(found, false); //-------> chạy xN lần compute <<<>>> 

		// nếu đúng --> chạy for()
		for (int i = 0; i < (int)found.size() && !endOfSearch; i++) {
			ITEM it = found[i];
			std::string addr = secp->GetAddress(it.mode, it.hash);
			if (checkPrivKey(addr, keys[it.thId], it.incr, it.mode)) {
				nbFoundKey++;
			}
		}

		if (ok) {
			// tính toán số keys cho từng thread  
			for (int i = 0; i < nbThread; i++) { // nbThread = 6144  //STEP_SIZE (1024*2)
				keys[i].Add((uint64_t)STEP_SIZE); // set keys[i] chi tiết cho từng lần quét - dựa trên gốc là keys[i] tổng thể
						if (i==0 || i==1 || i==2 || i == nbThread-2 || i == nbThread-1 || i == nbThread){
							std::cout<<std::endl<<" keys["<<i<<"] : "<<keys[i].GetBase16().c_str(); 
						}
			}
			
			counters[thId] += (uint64_t)(STEP_SIZE)*nbThread; // 12582912 = 1024x2 * 6144   // thId = 128 
			printf("\n --- counters : %lu -----  \n\n",counters[thId] );
		}
	}


	delete[] keys;
	delete[] p;
	delete GPU_Engine;

	ph->isRunning = false;

}


bool GPUEngine::SetKeys(Point* p)
{
	printf("\ng:::::::::::: GPUEngine::SetKeys()   ::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::\n");

	// Sets the starting keys for each thread 	// p must contains nbThread public keys
	for (int i = 0; i < nbThread; i += nbThreadPerGroup) { //nbThread = 6144 -- nbThreadPerGroup = 128 

		for (int j = 0; j < nbThreadPerGroup; j++) {

			inputKeyPinned[8 * i + j + 0 * nbThreadPerGroup] = p[i + j].x.bits64[0];
			inputKeyPinned[8 * i + j + 1 * nbThreadPerGroup] = p[i + j].x.bits64[1];
			inputKeyPinned[8 * i + j + 2 * nbThreadPerGroup] = p[i + j].x.bits64[2];
			inputKeyPinned[8 * i + j + 3 * nbThreadPerGroup] = p[i + j].x.bits64[3];

			inputKeyPinned[8 * i + j + 4 * nbThreadPerGroup] = p[i + j].y.bits64[0];
			inputKeyPinned[8 * i + j + 5 * nbThreadPerGroup] = p[i + j].y.bits64[1];
			inputKeyPinned[8 * i + j + 6 * nbThreadPerGroup] = p[i + j].y.bits64[2];
			inputKeyPinned[8 * i + j + 7 * nbThreadPerGroup] = p[i + j].y.bits64[3];

						// printf("\n[0] : %lu", p[i + j].x.bits64[0] );

						// std::cout<<std::endl<<"inputKeyPinned["<< 8 * i + j + 0 * nbThreadPerGroup <<"] 	p["<<i+j<<"].x.bits64[0] : "<<inputKeyPinned[8 * i + j + 0 * nbThreadPerGroup].GetBase16().c_str() ;
						// std::cout<<std::endl<<"inputKeyPinned["<< 8 * i + j + 1 * nbThreadPerGroup <<"] 	p["<<i+j<<"].x.bits64[1] : "<<inputKeyPinned[8 * i + j + 1 * nbThreadPerGroup].GetBase16().c_str() ;
						// std::cout<<std::endl<<"inputKeyPinned["<< 8 * i + j + 2 * nbThreadPerGroup <<"] 	p["<<i+j<<"].x.bits64[2] : "<<inputKeyPinned[8 * i + j + 2 * nbThreadPerGroup].GetBase16().c_str() ;
						// std::cout<<std::endl<<"inputKeyPinned["<< 8 * i + j + 3 * nbThreadPerGroup <<"] 	p["<<i+j<<"].x.bits64[3] : "<<inputKeyPinned[8 * i + j + 3 * nbThreadPerGroup].GetBase16().c_str() ;
						// std::cout<<std::endl<<"--------------------------------------------------------------------";
						// std::cout<<std::endl<<"inputKeyPinned["<< 8 * i + j + 4 * nbThreadPerGroup <<"] 	p["<<i+j<<"].y.bits64[0] : "<<inputKeyPinned[8 * i + j + 4 * nbThreadPerGroup].GetBase16().c_str() ;
						// std::cout<<std::endl<<"inputKeyPinned["<< 8 * i + j + 5 * nbThreadPerGroup <<"] 	p["<<i+j<<"].y.bits64[1] : "<<inputKeyPinned[8 * i + j + 5 * nbThreadPerGroup].GetBase16().c_str() ;
						// std::cout<<std::endl<<"inputKeyPinned["<< 8 * i + j + 6 * nbThreadPerGroup <<"] 	p["<<i+j<<"].y.bits64[2] : "<<inputKeyPinned[8 * i + j + 6 * nbThreadPerGroup].GetBase16().c_str() ;
						// std::cout<<std::endl<<"inputKeyPinned["<< 8 * i + j + 7 * nbThreadPerGroup <<"] 	p["<<i+j<<"].y.bits64[3] : "<<inputKeyPinned[8 * i + j + 7 * nbThreadPerGroup].GetBase16().c_str() ;
						// std::cout<<std::endl;
		}
	}

	// Fill device memory
	CudaSafeCall(cudaMemcpy(inputKey, inputKeyPinned, nbThread * 32 * 2, cudaMemcpyHostToDevice));

	CudaSafeCall(cudaFreeHost(inputKeyPinned));
	inputKeyPinned = NULL;


	//gộp callKernelSEARCH_MODE_S_A() // return callKernelSEARCH_MODE_S_A();
	CudaSafeCall(cudaMemset(outputBuffer, 0, 4));

	printf("\n========= trước compute_keys.... trong SETKEY()---------\n");
	compute_keys_comp_mode_sa <<< nbThread / nbThreadPerGroup, nbThreadPerGroup >>>(compMode, inputHashORxpoint, inputKey, maxFound, outputBuffer);
	printf("\n========= sauuuuuuuuuu compute_keys.... trong SETKEY()---------\n");

	return true;
}


__global__ void compute_keys_comp_mode_sa(uint32_t mode, uint32_t* hash160, uint64_t* __inputKey, uint32_t maxFound, uint32_t* out_found)
{
	int xPtr = (blockIdx.x * blockDim.x) * 8;
	int yPtr = xPtr + 4 * blockDim.x;

		// gộp hàm ComputeKeysSEARCH_MODE_SA()
		uint64_t* startx = __inputKey + xPtr; 
		uint64_t* starty = __inputKey + yPtr;

		uint64_t dx[GRP_SIZE / 2 + 1][4];  //khai báo mảng để lưu trữ các giá trị delta x.
		uint64_t px[4]; 
		uint64_t py[4];
		uint64_t pyn[4];
		uint64_t sx[4];
		uint64_t sy[4];
		uint64_t dy[4];
		uint64_t _s[4];
		uint64_t _p2[4]; // Khai báo các mảng khác để lưu trữ các giá trị tạm thời.

		// Load starting key
		__syncthreads();    //Đồng bộ hóa các luồng trong block hiện tại.
		Load256A(sx, startx);
		Load256A(sy, starty);
		Load256(px, sx);
		Load256(py, sy);   // Tải các giá trị bắt đầu vào các mảng sx, sy, px, py

		// Fill group with delta x
		uint32_t i;
		for (i = 0; i < HSIZE; i++)    // Tính toán các giá trị delta x cho nhóm điểm.
			ModSub256(dx[i], Gx + 4 * i, sx);
		ModSub256(dx[i], Gx + 4 * i, sx);   // For the first point
		ModSub256(dx[i + 1], _2Gnx, sx); // For the next center point

		// Compute modular inverse
		_ModInvGrouped(dx);   // Tính toán nghịch đảo modulo cho các giá trị delta x.

		// We use the fact that P + i*G and P - i*G has the same deltax, so the same inverse
		// We compute key in the positive and negative way from the center of the group

		// Check starting point
		
		CHECK__HASH(GRP_SIZE / 2); //GRP_SIZE = 1024*2  // Gọi hàm kiểm tra hash cho điểm khởi đầu.
		//CHECK__HASH(incr) Check__Hash(mode, px, py, incr, hash160, maxFound, out_found)
		
		ModNeg256(pyn, py);  // Tính giá trị âm của py

		
		//Trong vòng lặp, các phép toán được thực hiện để tính toán các giá trị x và y cho từng điểm trên đường cong và kiểm tra chúng với hash tương ứng
		for (i = 0; i < HSIZE; i++) {   // HSIZE (GRP_SIZE / 2 - 1) 

			// P = StartPoint + i*G
			Load256(px, sx);
			Load256(py, sy);
			ModSub256(dy, Gy + 4 * i, py);

			_ModMult(_s, dy, dx[i]);             //  s = (p2.y-p1.y)*inverse(p2.x-p1.x)
			_ModSqr(_p2, _s);                    // _p2 = pow2(s)

			ModSub256(px, _p2, px);
			ModSub256(px, Gx + 4 * i);           // px = pow2(s) - p1.x - p2.x;

			ModSub256(py, Gx + 4 * i, px);
			_ModMult(py, _s);                    // py = - s*(ret.x-p2.x)
			ModSub256(py, Gy + 4 * i);           // py = - p2.y - s*(ret.x-p2.x);

			CHECK__HASH(GRP_SIZE / 2 + (i + 1));    
			//CHECK__HASH(incr) Check__Hash(mode, px, py, incr, hash160, maxFound, out_found)

			// P = StartPoint - i*G, if (x,y) = i*G then (x,-y) = -i*G
			Load256(px, sx);   
			ModSub256(dy, pyn, Gy + 4 * i);

			_ModMult(_s, dy, dx[i]);            //  s = (p2.y-p1.y)*inverse(p2.x-p1.x)
			_ModSqr(_p2, _s);                   // _p = pow2(s)

			ModSub256(px, _p2, px);
			ModSub256(px, Gx + 4 * i);          // px = pow2(s) - p1.x - p2.x;

			ModSub256(py, px, Gx + 4 * i);
			_ModMult(py, _s);                   // py = s*(ret.x-p2.x)
			ModSub256(py, Gy + 4 * i, py);      // py = - p2.y - s*(ret.x-p2.x);

			CHECK__HASH(GRP_SIZE / 2 - (i + 1));   
			//CHECK__HASH(incr) Check__Hash(mode, px, py, incr, hash160, maxFound, out_found)
		}

		// First point (startP - (GRP_SZIE/2)*G)
		Load256(px, sx);
		Load256(py, sy);
		ModNeg256(dy, Gy + 4 * i);
		ModSub256(dy, py);

		_ModMult(_s, dy, dx[i]);              //  s = (p2.y-p1.y)*inverse(p2.x-p1.x)
		_ModSqr(_p2, _s);                     // _p = pow2(s)

		ModSub256(px, _p2, px);
		ModSub256(px, Gx + 4 * i);            // px = pow2(s) - p1.x - p2.x;

		ModSub256(py, px, Gx + 4 * i);
		_ModMult(py, _s);                     // py = s*(ret.x-p2.x)
		ModSub256(py, Gy + 4 * i, py);        // py = - p2.y - s*(ret.x-p2.x);

		
		CHECK__HASH(0);   //Kiểm tra hash cho điểm cuối cùng.
		//CHECK__HASH(incr) Check__Hash(mode, px, py, incr, hash160, maxFound, out_found)
		i++;


		//Cuối cùng, các giá trị x và y mới được lưu trở lại startx và starty
		// Next start point (startP + GRP_SIZE*G)
		Load256(px, sx);
		Load256(py, sy);
		ModSub256(dy, _2Gny, py);

		_ModMult(_s, dy, dx[i]);             //  s = (p2.y-p1.y)*inverse(p2.x-p1.x)
		_ModSqr(_p2, _s);                    // _p2 = pow2(s)

		ModSub256(px, _p2, px);
		ModSub256(px, _2Gnx);                // px = pow2(s) - p1.x - p2.x;

		ModSub256(py, _2Gnx, px);
		_ModMult(py, _s);                    // py = - s*(ret.x-p2.x)
		ModSub256(py, _2Gny);                // py = - p2.y - s*(ret.x-p2.x);

		// Update starting point
		__syncthreads();
		Store256A(startx, px);
		Store256A(starty, py);
	
}


bool GPUEngine::LaunchSEARCH_MODE_SA(std::vector<ITEM>& dataFound, bool spinWait) 
{
	// printf("\n	g:::::::::::: GPUEngine::LaunchSEARCH_MODE_S_A() ::::::::::::");

	dataFound.clear();

	// Get the result
	cudaEvent_t evt;
	CudaSafeCall(cudaEventCreate(&evt));
	CudaSafeCall(cudaMemcpyAsync(outputBufferPinned, outputBuffer, 4, cudaMemcpyDeviceToHost, 0));
	CudaSafeCall(cudaEventRecord(evt, 0));

	//The function enters a loop where it checks if the event has completed. 
	//If not, it sleeps for 1 millisecond to avoid busy-waiting.
	while (cudaEventQuery(evt) == cudaErrorNotReady) {  		
		Timer::SleepMillis(1);// Sleep 1 ms to free the CPU 
	}
	
	CudaSafeCall(cudaEventDestroy(evt));

	// Look for data found
	uint32_t nbFound = outputBufferPinned[0];

	// When can perform a standard copy, the kernel is eneded 
	CudaSafeCall(cudaMemcpy(outputBufferPinned, outputBuffer, nbFound * ITEM_SIZE_A + 4, cudaMemcpyDeviceToHost)); // ITEM_SIZE_A = 28


	for (uint32_t i = 0; i < nbFound; i++) { 
		printf("\n         check             check         -- nếu đúng mới chạy    for -> launch() \n");

		uint32_t* itemPtr = outputBufferPinned + (i * ITEM_SIZE_A32 + 1);
		ITEM it;
		it.thId = itemPtr[0];
		int16_t* ptr = (int16_t*)&(itemPtr[1]);
		//it.endo = ptr[0] & 0x7FFF;
		it.mode = (ptr[0] & 0x8000) != 0;
		it.incr = ptr[1]; //hiiu....
		it.hash = (uint8_t*)(itemPtr + 2);
		dataFound.push_back(it);
	}
	
	// gộp callKernelSEARCH_MODE_S_A() // return callKernelSEARCH_MODE_S_A();
	CudaSafeCall(cudaMemset(outputBuffer, 0, 4));

	printf("\n========= trước compute_keys.... trong launch()---------\n");
	compute_keys_comp_mode_sa <<< nbThread / nbThreadPerGroup, nbThreadPerGroup >>>(compMode, inputHashORxpoint, inputKey, maxFound, outputBuffer);
	printf("\n========= sauuuuuuuuuu compute_keys.... trong launch()---------");

	return true;
}


// # ///////////////// 
// # Overview
// # The code appears to be part of a GPU-accelerated key hunting application, likely used for cryptographic purposes such as Bitcoin key recovery. The main components involve generating keys, computing their corresponding public keys, and searching for a specific target using parallel processing on a GPU.

// # Key Functions
// # getGPUStartingKeys:

// # This function generates starting keys for each thread and computes their corresponding public keys.
// # It calculates the range of keys each thread will handle based on the total range and the number of threads (nbThread).
// # For each thread, it sets a starting key and computes the public key using the secp->ComputePublicKey(&k) function.
// # Key Points:

// # Key Range Calculation: The keys are distributed across threads based on the provided start and end range. Each thread computes its starting key by adding a portion of the range (determined by tRangeDiff) to the start key.
// # Public Key Computation: After computing the starting keys, public keys are generated and stored in an array (p).
// # FindKeyGPU:

// # This function orchestrates the key finding process using GPU resources.
// # It initializes the GPU engine, sets up key data, and enters a loop where it continuously searches for valid keys until a specified condition (endOfSearch) is met.
// # Key Points:

// # GPU Engine Initialization: A new GPUEngine object is created, which handles GPU-specific operations.
// # Thread Handling: The function utilizes multiple threads (nbThread = 6144) to increase the search efficiency.
// # Dynamic Key Adjustment: After each search cycle, the starting keys for each thread are incremented, allowing the search to progress through the key space.
// # SetKeys:

// # This function transfers the generated public keys to GPU memory for further computation.
// # It prepares the data in a format that can be processed by the GPU and triggers the computation of keys.
// # Key Points:

// # Data Transfer: Keys are copied to GPU memory using cudaMemcpy.
// # Kernel Launch: After preparing the keys, it launches the computation kernel (compute_keys_comp_mode_sa), which will perform the actual search for the specified keys.
// # compute_keys_comp_mode_sa (CUDA Kernel):

// # This kernel performs the heavy lifting of computing keys on the GPU.
// # It computes new potential public keys from the starting keys and checks them against a target hash.
// # Key Points:

// # Parallel Computation: Each thread computes a portion of the keyspace simultaneously, improving performance.
// # Modular Arithmetic: The kernel utilizes modular arithmetic for operations related to elliptic curve cryptography.
// # Key Validation: After computing potential keys, the kernel checks each key against the target hash to see if it matches.
// # Conclusion
// # Overall, this code leverages the power of GPU computing to perform a key search efficiently, using multiple threads to explore a large space of potential keys rapidly. The approach involves generating keys, computing their public representations, and validating these against specified criteria, making it suitable for applications in cryptographic contexts.

// # If you have specific areas you want more detail on or additional questions, let me know!



// # Bạn đã nói:
// # 	int xPtr = (blockIdx.x * blockDim.x) * 8;
// # 	int yPtr = xPtr + 4 * blockDim.x;

// # 	uint64_t* startx = __inputKey + xPtr; 
// # 	uint64_t* starty = __inputKey + yPtr; nghĩa là gì
// # ChatGPT đã nói:
// # ChatGPT
// # Let's break down the specific lines of code you mentioned from the compute_keys_comp_mode_sa CUDA kernel:

// # cpp
// # Sao chép mã
// # int xPtr = (blockIdx.x * blockDim.x) * 8;
// # int yPtr = xPtr + 4 * blockDim.x;

// # uint64_t* startx = __inputKey + xPtr; 
// # uint64_t* starty = __inputKey + yPtr;
// # Explanation
// # int xPtr = (blockIdx.x * blockDim.x) * 8;

// # blockIdx.x: This is the index of the current block within the grid. Each block can contain multiple threads.
// # blockDim.x: This represents the number of threads in the current block along the x-dimension.
// # The expression calculates the starting index for the x-coordinates of the keys for the current block. The multiplication by 8 suggests that each key occupies 8 consecutive memory slots (likely because each key consists of multiple components).

// # int yPtr = xPtr + 4 * blockDim.x;
// # This line calculates the starting index for the y-coordinates of the keys.
// # It offsets the xPtr by 4 * blockDim.x, indicating that the y-coordinates are stored after the x-coordinates in memory. Specifically, it suggests that for each key, there are four components (perhaps representing a 256-bit number, split across multiple uint64_t variables).


// # uint64_t* startx = __inputKey + xPtr;
// # This line creates a pointer (startx) that points to the starting address of the x-coordinates in the __inputKey array. The actual memory address is calculated by adding xPtr to the base address of __inputKey.


// # uint64_t* starty = __inputKey + yPtr;
// # Similarly, this line creates a pointer (starty) that points to the starting address of the y-coordinates in the __inputKey array.
// # Summary
// # In summary, these lines calculate the memory locations in the __inputKey array for the x and y coordinates of the keys for the current block. The calculations ensure that each block and thread accesses the correct portion of the key data, facilitating parallel processing on the GPU. The use of offsets allows efficient access to grouped data while maintaining alignment with the structure of the keys being processed.







// # // Allocate memory
// # nbThread = 6144
// # CudaSafeCall(cudaMalloc((void**)&inputKey, nbThread * 32 * 2));
// # CudaSafeCall(cudaHostAlloc(&inputKeyPinned, nbThread * 32 * 2, cudaHostAllocWriteCombined | cudaHostAllocMapped));


// # nbThread * 32 * 2: This expression calculates the total amount of memory to allocate.
// # nbThread (6144) is the number of threads.
// # 32 likely represents the size (in bytes) of data each thread will handle (perhaps each key consists of multiple components).
// # 2 indicates that each key is represented using two components (for example, a point in elliptic curve cryptography might require both x and y coordinates).
// # Overall, this line allocates enough memory on the GPU for 6144 keys, with each key being 64 bytes (32 bytes for x and 32 bytes for y).


